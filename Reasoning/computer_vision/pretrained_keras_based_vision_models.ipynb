{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reasoning {Vision} - Pretrained_models_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pankajr141/experiments/blob/master/Reasoning/Reasoning%20%7BVision%7D%20-%20Pretrained_models_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwhAO931Q2qp",
        "colab_type": "code",
        "outputId": "e949b1a1-3955-4f58-b9d8-bb0d941d5043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(r'/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BncN-vtjSIVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nwEgXDQRzuk",
        "colab_type": "text"
      },
      "source": [
        "## Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkt-IN26Q8zk",
        "colab_type": "text"
      },
      "source": [
        "<font face=\"Charis SIL\">The objective of this exercise is to demonstrate how can we use pretrained models on simple classification tasks. \n",
        "\n",
        "Here we will download famous models and will train the models on classification task and will see their output</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy3mJOmBR-Uw",
        "colab_type": "code",
        "outputId": "7958feb1-2da9-4893-9924-b71e2be8ec15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications import resnet50\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPFr4QHBhSNe",
        "colab_type": "code",
        "outputId": "78aade5d-a51b-4508-81a2-3fa0ae9df8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://static.independent.co.uk/s3fs-public/thumbnails/image/2018/03/18/15/billgates.jpg?width=668"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-23 11:30:36--  https://static.independent.co.uk/s3fs-public/thumbnails/image/2018/03/18/15/billgates.jpg?width=668\n",
            "Resolving static.independent.co.uk (static.independent.co.uk)... 151.101.1.184, 151.101.65.184, 151.101.129.184, ...\n",
            "Connecting to static.independent.co.uk (static.independent.co.uk)|151.101.1.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23093 (23K) [image/jpeg]\n",
            "Saving to: ‘billgates.jpg?width=668’\n",
            "\n",
            "\rbillgates.jpg?width   0%[                    ]       0  --.-KB/s               \rbillgates.jpg?width 100%[===================>]  22.55K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-12-23 11:30:36 (2.21 MB/s) - ‘billgates.jpg?width=668’ saved [23093/23093]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqa648d0jgfg",
        "colab_type": "text"
      },
      "source": [
        "## Pretrained Models\n",
        "\n",
        "https://keras.io/applications/\n",
        "\n",
        "<font face=\"Charis SIL\">\n",
        "\n",
        "*   Xception\n",
        "*   VGG16\n",
        "*   VGG19\n",
        "*   ResNet\n",
        "*   ResNetV2\n",
        "*   InceptionV3\n",
        "*   InceptionResNetV2\n",
        "*   MobileNet\n",
        "*   MobileNetV2\n",
        "*   DenseNet\n",
        "*   NASNet\n",
        "\n",
        "Lets pick one and see what can we do with it, all the other models exposes a similar interface of use.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI5woHnKjbrz",
        "colab_type": "text"
      },
      "source": [
        "### Resnet 50\n",
        "\n",
        "When trying to run with tensorflow-2.0.0 below error<br>\n",
        "\n",
        "<font color='red'>\n",
        "RuntimeError: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRtIPrzkmxG-",
        "colab_type": "text"
      },
      "source": [
        "<b>Predict using existing model</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAVf8S-noE69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = 'billgates.jpg?width=668'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)  # Add 4th Dimention appering at axis 0\n",
        "'''preprocess_input - transforming from [0-255] scale to other scale, which can contain -ve values\n",
        "https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py'''\n",
        "x = resnet50.preprocess_input(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YNWniadg_fk",
        "colab_type": "code",
        "outputId": "7cba2607-1a51-45b3-a0b0-fd67aa810665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = resnet50.ResNet50(weights='imagenet')\n",
        "preds = model.predict(x)\n",
        "print('Predicted:', resnet50.decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "Predicted: [('n04350905', 'suit', 0.75385237), ('n04591157', 'Windsor_tie', 0.09281588), ('n02865351', 'bolo_tie', 0.023333998)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQRCWIpbnSbF",
        "colab_type": "text"
      },
      "source": [
        "<b>Features only</b>\n",
        "\n",
        "We can freeze fully connected layers to include output from VGG Convolution only\n",
        "\n",
        "https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE6XNjaFm7Vl",
        "colab_type": "code",
        "outputId": "3ec72bd1-90c9-40c5-f5b6-205d9d9c3cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
        "features = model.predict(x)\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Features shape:\", features.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: (1, 224, 224, 3)\n",
            "Features shape: (1, 7, 7, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf2q580haSci",
        "colab_type": "text"
      },
      "source": [
        "## Retrain VGG 16 Model on Mnist dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyw10CRWonES",
        "colab_type": "text"
      },
      "source": [
        "<b>Freeze all convolution layers - use all layers </b>\n",
        "\n",
        "We will freeze the convolution layers and will train fully connected layers on new dataset\n",
        "\n",
        "Lets download mnist dataset and convert it into a format "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVWLcGs9124P",
        "colab_type": "code",
        "outputId": "9135e379-3d13-44fc-933b-4c1935ae3868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "num_classes = 10\n",
        "# x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "\n",
        "# Convert 1D to 3D\n",
        "x_train = np.stack((x_train,)*3, axis=-1)\n",
        "x_test = np.stack((x_test,)*3, axis=-1)\n",
        "\n",
        "x_train = np.array([cv2.resize(image, (32, 32)) for image in x_train])\n",
        "x_test = np.array([cv2.resize(image, (32, 32)) for image in x_test])\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,)\n",
            "(60000, 32, 32, 3) (60000, 10) (10000, 32, 32, 3) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67dSN9atXHBt",
        "colab_type": "text"
      },
      "source": [
        "Lets visualize our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My9KWHeq7wc0",
        "colab_type": "code",
        "outputId": "db369107-93a6-4212-e53e-f17f68fdbe67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for i in range(2):\n",
        "  print(y_train[i])\n",
        "  plt.imshow(x_train[i])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAARkklEQVR4nO3da4xVVZrG8f8rFiiN3J2iRBR0Sowa\nBS1BHGx6utNGsRMlUaNxJn4gTWfS6pj0fDBOnHb8ZE9GDYmJYzkS6Y4iooBo1GnHS7QTUW7KVRAQ\nAiVUiYAg4Vq88+FsZgrnvLuKcwXW80tInVrvWXUWG57ap/aqvZa5OyJy+juj3gMQkdpQ2EUSobCL\nJEJhF0mEwi6SCIVdJBFnltPZzG4CpgO9gP9098e7eb7m+USqzN2tWLuVOs9uZr2AdcAvga3AIuBu\nd1+d00dhF6myKOzlvI0fB6x3943ufgh4Gbi1jK8nIlVUTtiHA1u6fL41axORk1BZP7P3hJlNA6ZV\n+3VEJF85YW8DRnT5/Pys7Tju3gq0gn5mF6mnct7GLwKazWyUmfUG7gIWVGZYIlJpJZ/Z3f2Imd0H\n/BeFqbcZ7r6qYiMTkYoqeeqtpBfT23iRqqvG1JuInEIUdpFEKOwiiVDYRRKhsIskQmEXSYTCLpII\nhV0kEQq7SCIUdpFEKOwiiVDYRRKhsIskQmEXSYTCLpIIhV0kEQq7SCIUdpFEKOwiiVDYRRKhsIsk\nQmEXSYTCLpIIhV0kEQq7SCLK2sXVzDYBe4FO4Ii7t1RiUFJ5Z5wRf18/88zKb+bb2NhYtL1fv35h\nnz59+oS1AwcOhLXt27eHtUsuuaRo+7Bhw8I+edra/t/epf9r48aNYW3Xrl0lvV4lVeJf+W/dfUcF\nvo6IVJHexoskotywO/BnM1tiZtMqMSARqY5y38ZPdPc2M/sr4F0z+9LdP+r6hOybgL4RiNRZWWd2\nd2/LPnYA84BxRZ7T6u4tungnUl8lh93MfmJm5xx7DNwIrKzUwESkssp5G98IzDOzY1/nJXd/pyKj\nOo00NDSEtezYFZU3DdW3b9+wdtZZZ51QO8TTZOWYOHFi0faRI0eGfQYMGBDWvvnmm7D2/vvvh7UH\nHnigaPsNN9wQ9smb5ps9e3ZYe/bZZ8PaKT315u4bgasqOBYRqSJNvYkkQmEXSYTCLpIIhV0kEQq7\nSCIqf7tTgnr16hXWLrjggrCWdwfYqFGjwtqYMWPCWnNzc9H2pqamsM+kSZPCWi3t3r07rK1fvz6s\nRX9ngPHjxxdtz5sK++qrr8LaZ599Ftby7r47GejMLpIIhV0kEQq7SCIUdpFEKOwiiTB3r92LmdXu\nxaoguup+6aWXhn2efvrpsHbFFVeEtd69e4e1vDXjorXmar0GXSTv/1veDS2zZs0Ka/v37w9r0b9Z\nR0dH2CfvSn3eOnN5swlHjx4Na5Xm7kXvsNKZXSQRCrtIIhR2kUQo7CKJUNhFEqGwiyRCN8KcgGj6\n5Ntvvw37HDp0KKzlrQuXt85cpXV2doa1tWvXhrW9e/eGtehGnv79+4d9Vq9eHdbmz58f1kqZ1jpy\n5EhYyzseef+etZxeK4XO7CKJUNhFEqGwiyRCYRdJhMIukgiFXSQR3U69mdkM4FdAh7tfkbUNBmYD\nI4FNwJ3uXv/9baosumMr7y6pV199Nax99913YS1va6gRI0aEtQkTJhRtz5syyltz7ZFHHglrO3bs\nCGvRNk/R+CB/6u1k2D7pVNeTM/sLwE0/ansIeM/dm4H3ss9F5CTWbdiz/dZ3/qj5VmBm9ngmcFuF\nxyUiFVbqz+yN7r4te7ydwo6uInISK/vXZd3d81agMbNpwLRyX0dEylPqmb3dzJoAso/hGj/u3uru\nLe7eUuJriUgFlBr2BcC92eN7gdcrMxwRqZaeTL3NAn4GDDWzrcDvgceBV8xsKrAZuLOagzzZHT58\nOKy9/fbbYW3dunVhLe/Oq2uvvTasDRkypGj7oEGDwj4LFiwIa3mLQP7www9hbfny5UXbV6xYEfY5\ncOBAWJPydRt2d787KP2iwmMRkSrSb9CJJEJhF0mEwi6SCIVdJBEKu0gitOBklW3dujWstbe3h7W8\nPdEaGhrC2oYNG4q2X3PNNWGfgwcPhrW8hRnzxhgtRhlNyUn16cwukgiFXSQRCrtIIhR2kUQo7CKJ\nUNhFEqGptzrKu1suT0dHuHxAuDfb2LFjwz4333xzWHvppZfC2ubNm8Na3pSd1IfO7CKJUNhFEqGw\niyRCYRdJhMIukghdjT8FRVfcAebMmVO0vbm5OewzadKksJZ3pf6DDz4Ia9HWUHv27An77N+/P6xJ\n+XRmF0mEwi6SCIVdJBEKu0giFHaRRCjsIomwvHXEAMxsBvAroMPdr8jaHgV+DXybPe1hd3+r2xfL\n2e1VKqNv375F2ydOnBj2mTlzZljLu1ln2bJlYS3a5unNN98M+yxZsiSslboWXorc3Yq19+TM/gJw\nU5H2p9x9TPan26CLSH11G3Z3/wjYWYOxiEgVlfMz+31mttzMZphZvEWoiJwUSg37M8DFwBhgG/BE\n9EQzm2Zmi81scYmvJSIVUFLY3b3d3Tvd/SjwHDAu57mt7t7i7i2lDlJEyldS2M2sqcunU4CVlRmO\niFRLT6beZgE/A4YC7cDvs8/HAA5sAn7j7tu6fTFNvVWdWdFZFwYPHhz2mTJlSlh77LHHwtrAgQPD\nWvT/Km/q7YUXXghrn3zySVjbvXt3WEtRNPXW7S2u7n53kebnyx6RiNSUfoNOJBEKu0giFHaRRCjs\nIolQ2EUSoQUnTzPRlFfe9NS8efPCWnt7e1ibOnVqWIvusrvxxhvDPv379w9r5557bljLm87buVO3\ndRyjM7tIIhR2kUQo7CKJUNhFEqGwiyRCYRdJhKbeEtHZ2RnW8qanPvzww5L6LVy4sGj77bffHvYZ\nP358WOvXr19YGzQoXihp+vTpYS01OrOLJEJhF0mEwi6SCIVdJBEKu0gidDVecrdP2rt3b1hbtGhR\nWNuyZUvR9tGjR4d9rrrqqrA2ZsyYsHbgwIGw9sYbbxRt37RpU9jn6NGjYe1UpjO7SCIUdpFEKOwi\niVDYRRKhsIskQmEXSUS3U29mNgL4I9BIYbunVnefbmaDgdnASApbQN3p7ruqN1SplmjLKMjfNurC\nCy8Ma42NjUXb825ayRtHr169wlqfPn1K+pqp6cmZ/QjwO3e/DLgO+K2ZXQY8BLzn7s3Ae9nnInKS\n6jbs7r7N3Zdmj/cCa4DhwK3AzOxpM4HbqjVIESnfCf3MbmYjgbHAp0Bjl51bt1N4my8iJ6ke/7qs\nmfUDXgMedPc9XX8WcnePtmM2s2nAtHIHKiLl6dGZ3cwaKAT9RXefmzW3m1lTVm8COor1dfdWd29x\n95ZKDFhEStNt2K1wCn8eWOPuT3YpLQDuzR7fC7xe+eGJSKX05G383wB/D6wws8+ztoeBx4FXzGwq\nsBm4szpDlBNx5pnF/0kHDBgQ9smbQhs7dmxYmzBhQlhrbm4u2p5311ueffv2hbW8O9g2btxYtD3v\nTr/TVbdhd/e/ANFk5S8qOxwRqRb9Bp1IIhR2kUQo7CKJUNhFEqGwiyRCC06epPLu8jr77LPDWlNT\nU9H2cePGhX2mTJkS1vKm14YOHRrWoinAQ4cOhX127NgR1tavXx/WVq9eHdZSnGKL6MwukgiFXSQR\nCrtIIhR2kUQo7CKJUNhFEqGptyrLW/DwjDPi77VDhgwJay0t8dIAt91WfHWwW265JewzbNiwsJan\ns7MzrO3fv79oe94dam+99VZYe/nll8Pa0qVLw5r8H53ZRRKhsIskQmEXSYTCLpIIhV0kEboaX2V5\n2x3lrf12zz33hLXoijvAeeedV7S9oaEh7FOqtWvXhrU5c+YUbV+wYEHYZ926dWHt4MGDPR+YFKUz\nu0giFHaRRCjsIolQ2EUSobCLJEJhF0lEt1NvZjYC+COFLZkdaHX36Wb2KPBr4NvsqQ+7e3wnwyki\nb+236OaU+++/P+xz+eWXh7VRo0aFtWgKDWDgwIFhLVr7LboxBWDlypVhbe7cuWHt448/Dmtff/11\n0fZdu3aFfTS9Vl09mWc/AvzO3Zea2TnAEjN7N6s95e7/Xr3hiUil9GSvt23AtuzxXjNbAwyv9sBE\npLJO6Gd2MxsJjAU+zZruM7PlZjbDzOJfFRORuutx2M2sH/Aa8KC77wGeAS4GxlA48z8R9JtmZovN\nbHEFxisiJepR2M2sgULQX3T3uQDu3u7une5+FHgOKLoLgbu3unuLu8fLq4hI1XUbdiusq/Q8sMbd\nn+zS3nXrkSlAfElXROrOutsex8wmAh8DK4CjWfPDwN0U3sI7sAn4TXYxL+9r1Wwvnry7za688sqw\nNmnSpLA2evToou3XX3992Cdvmqxv375hLZpCg/y139ra2oq2v/POO2Gf6A41yL+zLW+7pmibJ23H\nVH3uXnThw55cjf8LUKzzKT+nLpIS/QadSCIUdpFEKOwiiVDYRRKhsIsk4rRdcHL48PjX9ydPnhzW\n7rjjjrA2dOjQou15U2g7d+4Ma8uWLQtr33//fVjbvHlzWFu4cGHR9rwtklatWhXWDh8+HNbk1KIz\nu0giFHaRRCjsIolQ2EUSobCLJEJhF0nEaTv1tm/fvrD25ZdfhrX58+dXdBx5U28bNmwIa3v27Alr\nW7ZsCWvR3y26C03SoTO7SCIUdpFEKOwiiVDYRRKhsIskQmEXSUS3C05W9MVquOCkSKqiBSd1ZhdJ\nhMIukgiFXSQRCrtIIhR2kUT0ZK+3s8zsMzP7wsxWmdm/Zu2jzOxTM1tvZrPNrHf1hysiperJmf0g\n8HN3v4rC3m43mdl1wB+Ap9z9r4FdwNTqDVNEytVt2L3gh+zThuyPAz8HXs3aZwK3VWWEIlIRPd2f\nvZeZfQ50AO8CG4Dd7n4ke8pWIF67WUTqrkdhd/dOdx8DnA+MAy7t6QuY2TQzW2xmi0sco4hUwAld\njXf33cAHwARgoJkdW+nmfKDoxuDu3uruLe7eUtZIRaQsPbkaf66ZDcwenw38ElhDIfS3Z0+7F3i9\nWoMUkfJ1eyOMmV1J4QJcLwrfHF5x98fM7CLgZWAwsAz4O3c/2M3X0o0wIlUW3Qiju95ETjO6600k\ncQq7SCIUdpFEKOwiiVDYRRJR6+2fdgCbs8dDs8/rTeM4nsZxvFNtHBdGhZpOvR33wmaLT4bfqtM4\nNI5UxqG38SKJUNhFElHPsLfW8bW70jiOp3Ec77QZR91+ZheR2tLbeJFE1CXsZnaTma3NFqt8qB5j\nyMaxycxWmNnntVxcw8xmmFmHma3s0jbYzN41s6+yj4PqNI5HzawtOyafm9nkGoxjhJl9YGars0VN\n/zFrr+kxyRlHTY9J1RZ5dfea/qFwq+wG4CKgN/AFcFmtx5GNZRMwtA6v+1PgamBll7Z/Ax7KHj8E\n/KFO43gU+KcaH48m4Ors8TnAOuCyWh+TnHHU9JgABvTLHjcAnwLXAa8Ad2Xt/wH8w4l83Xqc2ccB\n6919o7sfonBP/K11GEfduPtHwM4fNd9KYd0AqNECnsE4as7dt7n70uzxXgqLowynxsckZxw15QUV\nX+S1HmEfDmzp8nk9F6t04M9mtsTMptVpDMc0uvu27PF2oLGOY7nPzJZnb/Or/uNEV2Y2EhhL4WxW\nt2Pyo3FAjY9JNRZ5Tf0C3UR3vxq4Gfitmf203gOCwnd2Ct+I6uEZ4GIKewRsA56o1QubWT/gNeBB\nd9/TtVbLY1JkHDU/Jl7GIq+ReoS9DRjR5fNwscpqc/e27GMHMI/CQa2XdjNrAsg+dtRjEO7env1H\nOwo8R42OiZk1UAjYi+4+N2uu+TEpNo56HZPstU94kddIPcK+CGjOriz2Bu4CFtR6EGb2EzM759hj\n4EZgZX6vqlpAYeFOqOMCnsfClZlCDY6JmRnwPLDG3Z/sUqrpMYnGUetjUrVFXmt1hfFHVxsnU7jS\nuQH45zqN4SIKMwFfAKtqOQ5gFoW3g4cp/Ow1FRgCvAd8Bfw3MLhO4/gTsAJYTiFsTTUYx0QKb9GX\nA59nfybX+pjkjKOmxwS4ksIirsspfGP5ly7/Zz8D1gNzgD4n8nX1G3QiiUj9Ap1IMhR2kUQo7CKJ\nUNhFEqGwiyRCYRdJhMIukgiFXSQR/wP5NwffUonnaQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEJhF0mEwi6SiP8DLw7cBf3qKl8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh10NslUKmwr",
        "colab_type": "text"
      },
      "source": [
        "We are going to import a pretrained model by passing weights='imagenet'. Then we are going to change the input tensor size in model so that our data which is 28x28x3 can be fed and trained, otherwise we need to resize our dataset accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkZEhEaDol13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine.input_layer import Input\n",
        "from keras.applications import vgg16\n",
        "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(32, 32, 3))) \n",
        "# base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(28, 28, 3)))  # Changing the input shape of model ideally its different\n",
        "\n",
        "''' Below we will be  freezing all the base model layers, so that cannot be retrained.\n",
        "We can choose which layers we want to train and not train by setting the trainable flag. '''\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = False\n",
        "    # print(i, layer.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_hAiU_Ao7GA",
        "colab_type": "code",
        "outputId": "a632e1f6-6d0d-45ef-d277-787982cee7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "print(model.summary())\n",
        "optimizer=optimizers.Adam(lr=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=2, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# score = model.evaluate(x_test, y_test, verbose=1)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 15,250,250\n",
            "Trainable params: 535,562\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 740s 12ms/step - loss: 2.4297 - acc: 0.6796 - val_loss: 0.3688 - val_acc: 0.9069\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 739s 12ms/step - loss: 0.5856 - acc: 0.8569 - val_loss: 0.2176 - val_acc: 0.9320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a7c9fda90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti53XqOUOhjN",
        "colab_type": "text"
      },
      "source": [
        "<i>!!!!!!!! Hmm the accuracy is really bad, but we were able to ran the code, we will fine tune it later.</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "och_0NGjSBgX",
        "colab_type": "text"
      },
      "source": [
        "<b>Freeze all convolution layers - use first few layers </b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZZby-Q8svIQ",
        "colab_type": "code",
        "outputId": "194f0a68-e7dd-4a0f-e7f2-e07b37df0239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "from keras.engine.input_layer import Input\n",
        "from keras.applications import vgg16\n",
        "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(32, 32, 3))) \n",
        "# base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(28, 28, 3)))  # Changing the input shape of model ideally its different\n",
        "\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = False\n",
        "    print(layer.name, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_8 False\n",
            "block1_conv1 False\n",
            "block1_conv2 False\n",
            "block1_pool False\n",
            "block2_conv1 False\n",
            "block2_conv2 False\n",
            "block2_pool False\n",
            "block3_conv1 False\n",
            "block3_conv2 False\n",
            "block3_conv3 False\n",
            "block3_pool False\n",
            "block4_conv1 False\n",
            "block4_conv2 False\n",
            "block4_conv3 False\n",
            "block4_pool False\n",
            "block5_conv1 False\n",
            "block5_conv2 False\n",
            "block5_conv3 False\n",
            "block5_pool False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAfvpq0jtgoy",
        "colab_type": "code",
        "outputId": "bcf7528f-ff8f-4e88-e1db-72d273790245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.layers import Reshape, Flatten, Dropout\n",
        "\n",
        "# x = base_model.output\n",
        "x = base_model.get_layer('block3_pool').output  # Lets pick 3rd layer output\n",
        "x = Flatten()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# and a logistic layer -- let's say we have 10 classes\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "print(model.summary())\n",
        "optimizer=optimizers.Adam(lr=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=2, verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 5,941,066\n",
            "Trainable params: 4,205,578\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 506s 8ms/step - loss: 14.4751 - acc: 0.1019 - val_loss: 14.5353 - val_acc: 0.0982\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 503s 8ms/step - loss: 14.5485 - acc: 0.0974 - val_loss: 14.5353 - val_acc: 0.0982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a7c444860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDa6LXtD0CX9",
        "colab_type": "text"
      },
      "source": [
        "!!! so clipping last few layers doesn't work, possible reason could be the 3rd layer might not have relevent features and if we retrain last layer our result might improve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCtORKeJbPBI",
        "colab_type": "text"
      },
      "source": [
        "<b>Freeze all but last convolution layers - use all layers</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lOTof1mZhws",
        "colab_type": "code",
        "outputId": "956e3d67-5316-489b-f037-482fe1baa068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "from keras.engine.input_layer import Input\n",
        "from keras.applications import vgg16\n",
        "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(32, 32, 3))) \n",
        "# base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(28, 28, 3)))  # Changing the input shape of model ideally its different\n",
        "\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = False\n",
        "    if layer.name.startswith(\"block5\"):\n",
        "      layer.trainable = True\n",
        "    print(layer.name, layer.trainable)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 4s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "input_1 False\n",
            "block1_conv1 False\n",
            "block1_conv2 False\n",
            "block1_pool False\n",
            "block2_conv1 False\n",
            "block2_conv2 False\n",
            "block2_pool False\n",
            "block3_conv1 False\n",
            "block3_conv2 False\n",
            "block3_conv3 False\n",
            "block3_pool False\n",
            "block4_conv1 False\n",
            "block4_conv2 False\n",
            "block4_conv3 False\n",
            "block4_pool False\n",
            "block5_conv1 True\n",
            "block5_conv2 True\n",
            "block5_conv3 True\n",
            "block5_pool True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KXNwhiKZstQ",
        "colab_type": "code",
        "outputId": "598b81c8-8a97-459b-fc27-abc4c1e7b6fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.layers import Reshape, Flatten, Dropout\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "print(model.summary())\n",
        "optimizer=optimizers.Adam(lr=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#model.fit(x_train[:2000], y_train[:2000], batch_size=64, epochs=3, verbose=1, validation_data=(x_test[:2000], y_test[:2000]))\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=2, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# score = model.evaluate(x_test, y_test, verbose=1)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 15,250,250\n",
            "Trainable params: 7,614,986\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 2744s 46ms/step - loss: 0.4336 - acc: 0.8917 - val_loss: 0.0730 - val_acc: 0.9798\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 2755s 46ms/step - loss: 0.0720 - acc: 0.9815 - val_loss: 0.0665 - val_acc: 0.9826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbceaf6cba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTyIVeRBGCwD",
        "colab_type": "text"
      },
      "source": [
        "!!!! So by retraining last convolution layer scores have increased\n",
        "\n"
      ]
    }
  ]
}