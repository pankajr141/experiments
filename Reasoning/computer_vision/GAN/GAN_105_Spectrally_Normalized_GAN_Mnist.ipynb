{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_105_Spectrally_Normalized_GAN_Mnist.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMXQz6ZShyv5DrJgFZuqPl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pankajr141/experiments/blob/master/Reasoning/GAN/GAN_105_Spectrally_Normalized_GAN_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GcJnBcN4zkp"
      },
      "source": [
        "## Spectrally Normalized Generative Adversarial Networks (SN-GAN)\n",
        "\n",
        "This notebook enhances GAN102 by introducing Spectrally Normalized GAN.\n",
        "\n",
        "Here are the main features of SN-GAN\n",
        "\n",
        "* Introduce weight normalization to to stabilize the training of the discriminator. As a result, spectral normalization helps improve stability and avoid vanishing gradient problems, such as mode collapse.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Task\n",
        "MNIST Digit generation, build and train a Deep Convolution GAN that can generate hand-written images of digits (0-9).\n",
        "\n",
        "### Reference\n",
        "https://nbviewer.org/github/amanchadha/coursera-gan-specialization/blob/main/C1%20-%20Build%20Basic%20Generative%20Adversarial%20Networks/Week%203/SNGAN.ipynb\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJfn5m6A5Ltw"
      },
      "source": [
        "## Generator\n",
        "\n",
        "Since spectral normalization is only applied to the matrices in the discriminator, the generator implementation is the same as the original.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vRIE_uR4x-D"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    '''\n",
        "    Generator Class\n",
        "    Values:\n",
        "    z_dim: the dimension of the noise vector, a scalar\n",
        "    im_chan: the number of channels of the output image, a scalar\n",
        "            MNIST is black-and-white, so that's our default\n",
        "    hidden_dim: the inner dimension, a scalar\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        # Build the neural network\n",
        "        self.gen = nn.Sequential(\n",
        "            self.make_gen_block(z_dim, hidden_dim * 4),\n",
        "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
        "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
        "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
        "        )\n",
        "\n",
        "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
        "        '''\n",
        "        Function to return a sequence of operations corresponding to a generator block of the DCGAN, \n",
        "        corresponding to a transposed convolution, a batchnorm (except for in the last layer), and an activation\n",
        "        Parameters:\n",
        "        input_channels: how many channels the input feature representation has\n",
        "        output_channels: how many channels the output feature representation should have\n",
        "        kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
        "        stride: the stride of the convolution\n",
        "        final_layer: whether we're on the final layer (affects activation and batchnorm)\n",
        "        '''\n",
        "        # Build the neural block\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        else: # Final Layer\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.Tanh(),\n",
        "            )\n",
        "\n",
        "    def unsqueeze_noise(self, noise):\n",
        "        '''\n",
        "        Function for completing a forward pass of the Generator: Given a noise vector, \n",
        "        returns a copy of that noise with width and height = 1 and channels = z_dim.\n",
        "        Parameters:\n",
        "        noise: a noise tensor with dimensions (batch_size, z_dim)\n",
        "        '''\n",
        "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        '''\n",
        "        Function for completing a forward pass of the Generator: Given a noise vector, \n",
        "        returns a generated image.\n",
        "        Parameters:\n",
        "        noise: a noise tensor with dimensions (batch_size, z_dim)\n",
        "        '''\n",
        "        x = self.unsqueeze_noise(noise)\n",
        "        return self.gen(x)\n",
        "\n",
        "def get_noise(n_samples, z_dim, device='cpu'):\n",
        "    '''\n",
        "    Function for creating a noise vector: Given the dimensions (n_samples, z_dim)\n",
        "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
        "    Parameters:\n",
        "    n_samples: the number of samples in the batch, a scalar\n",
        "    z_dim: the dimension of the noise vector, a scalar\n",
        "    device: the device type\n",
        "    '''\n",
        "    return torch.randn(n_samples, z_dim, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUuqz58C-duL"
      },
      "source": [
        "## Discriminator\n",
        "\n",
        "\n",
        "For the discriminator, you can wrap each nn.Conv2d with nn.utils.spectral_norm\n",
        "\n",
        "\n",
        "spectral norm does not eliminate the need for batch norm. Spectral norm affects the weights of each layer, while batch norm affects the activations of each layer. You can see both in a discriminator architecture, but you can also see just one of them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA-M0wLo-deC"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    '''\n",
        "    Discriminator Class\n",
        "    Values:\n",
        "    im_chan: the number of channels of the output image, a scalar\n",
        "            MNIST is black-and-white (1 channel), so that's our default.\n",
        "    hidden_dim: the inner dimension, a scalar\n",
        "    '''\n",
        "\n",
        "    def __init__(self, im_chan=1, hidden_dim=16):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            self.make_disc_block(im_chan, hidden_dim),\n",
        "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
        "            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n",
        "        )\n",
        "\n",
        "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
        "        '''\n",
        "        Function to return a sequence of operations corresponding to a discriminator block of the DCGAN, \n",
        "        corresponding to a convolution, a batchnorm (except for in the last layer), and an activation\n",
        "        Parameters:\n",
        "        input_channels: how many channels the input feature representation has\n",
        "        output_channels: how many channels the output feature representation should have\n",
        "        kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
        "        stride: the stride of the convolution\n",
        "        final_layer: whether we're on the final layer (affects activation and batchnorm)\n",
        "        '''\n",
        "        \n",
        "        # Build the neural block\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.utils.spectral_norm(nn.Conv2d(input_channels, output_channels, kernel_size, stride)),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            )\n",
        "        else: # Final Layer\n",
        "            return nn.Sequential(\n",
        "                nn.utils.spectral_norm(nn.Conv2d(input_channels, output_channels, kernel_size, stride)),\n",
        "            )\n",
        "\n",
        "    def forward(self, image):\n",
        "        '''\n",
        "        Function for completing a forward pass of the Discriminator: Given an image tensor, \n",
        "        returns a 1-dimension tensor representing fake/real.\n",
        "        Parameters:\n",
        "        image: a flattened image tensor with dimension (im_dim)\n",
        "        '''\n",
        "        disc_pred = self.disc(image)\n",
        "        return disc_pred.view(len(disc_pred), -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P57-Wg5i_xyI"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDoL6JUrBO1n"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DimyySp6BR-5"
      },
      "source": [
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def show_tensor_images(image_tensor1, image_tensor2, num_images=25, size=(1, 28, 28)):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in a uniform grid.\n",
        "    '''\n",
        "    image_real = image_tensor1.detach().cpu().view(-1, *size)\n",
        "    image_grid_real = make_grid(image_real[:num_images], nrow=5)\n",
        "    image_grid_real = image_grid_real.permute(1, 2, 0).squeeze()\n",
        "\n",
        "    image_fake = image_tensor2.detach().cpu().view(-1, *size)\n",
        "    image_grid_fake = make_grid(image_fake[:num_images], nrow=5)\n",
        "    image_grid_fake = image_grid_fake.permute(1, 2, 0).squeeze()\n",
        "    img_sep = torch.ones(image_grid_fake.shape[1], 10 , image_grid_fake.shape[2])\n",
        "    #print(img_sep)\n",
        "    image_grid = np.concatenate([image_grid_real, img_sep, image_grid_fake], axis=1)\n",
        "    plt.imshow(image_grid)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkhgqc3M_9nG"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST # Training dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "n_epochs = 200\n",
        "z_dim = 64\n",
        "display_step = 500\n",
        "batch_size = 128\n",
        "lr = 0.0002 # A learning rate of 0.0002 works well on DCGAN\n",
        "\n",
        "# These parameters control the optimizer's momentum, which you can read more about here:\n",
        "# https://distill.pub/2017/momentum/ but you don’t need to worry about it for this course\n",
        "beta_1 = 0.5 \n",
        "beta_2 = 0.999\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# You can tranform the image values to be between -1 and 1 (the range of the tanh activation)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "\n",
        "# Load MNIST dataset as tensors\n",
        "dataloader = DataLoader(\n",
        "    MNIST('.', download=True, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YXVXHyDAX-X"
      },
      "source": [
        "gen = Generator(z_dim).to(device)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "disc = Discriminator().to(device) \n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "\n",
        "# We initialize the weights to the normal distribution\n",
        "# with mean 0 and standard deviation 0.02\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "gen = gen.apply(weights_init)\n",
        "disc = disc.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lnm_0zPiAjeM"
      },
      "source": [
        "training started .....\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_G2rABvAhPE"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "cur_step = 0\n",
        "mean_generator_loss = 0\n",
        "mean_discriminator_loss = 0\n",
        "for epoch in range(n_epochs):\n",
        "    # Dataloader returns the batches\n",
        "    for real, _ in tqdm(dataloader):\n",
        "        cur_batch_size = len(real)\n",
        "        real = real.to(device)\n",
        "\n",
        "        ## Update Discriminator ##\n",
        "        disc_opt.zero_grad()\n",
        "        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
        "        fake = gen(fake_noise)\n",
        "        disc_fake_pred = disc(fake.detach())\n",
        "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
        "        disc_real_pred = disc(real)\n",
        "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
        "        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
        "\n",
        "        # Keep track of the average discriminator loss\n",
        "        mean_discriminator_loss += disc_loss.item() / display_step\n",
        "        # Update gradients\n",
        "        disc_loss.backward(retain_graph=True)\n",
        "        # Update optimizer\n",
        "        disc_opt.step()\n",
        "\n",
        "        ## Update Generator ##\n",
        "        gen_opt.zero_grad()\n",
        "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
        "        fake_2 = gen(fake_noise_2)\n",
        "        disc_fake_pred = disc(fake_2)\n",
        "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "        # Keep track of the average generator loss\n",
        "        mean_generator_loss += gen_loss.item() / display_step\n",
        "\n",
        "        ## Visualization code ##\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
        "            show_tensor_images(real, fake, num_images=25, size=(1, 28, 28))\n",
        "            mean_generator_loss = 0\n",
        "            mean_discriminator_loss = 0\n",
        "        cur_step += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}