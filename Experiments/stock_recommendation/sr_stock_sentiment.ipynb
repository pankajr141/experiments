{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":223792675,"sourceType":"kernelVersion"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import sys\nimport logging\n\nlogger = logging.getLogger('stock_recommender')\nfor handler in logger.handlers[:]:\n    logger.removeHandler(handler)\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\nstream_handler = logging.StreamHandler(sys.stdout)\nstream_handler.setLevel(logging.DEBUG)\nstream_handler.setFormatter(formatter)\n\nlogger.addHandler(stream_handler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:42:09.173404Z","iopub.execute_input":"2025-02-25T04:42:09.173921Z","iopub.status.idle":"2025-02-25T04:42:09.180006Z","shell.execute_reply.started":"2025-02-25T04:42:09.173880Z","shell.execute_reply":"2025-02-25T04:42:09.178742Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -q --upgrade pymilvus langchain langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:59:02.663921Z","iopub.execute_input":"2025-02-25T04:59:02.664325Z","iopub.status.idle":"2025-02-25T04:59:15.662186Z","shell.execute_reply.started":"2025-02-25T04:59:02.664292Z","shell.execute_reply":"2025-02-25T04:59:15.659159Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!cp /kaggle/input/sr-data-gathering-news/stock_recommender.db .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:42:21.561237Z","iopub.execute_input":"2025-02-25T04:42:21.561559Z","iopub.status.idle":"2025-02-25T04:42:21.716668Z","shell.execute_reply.started":"2025-02-25T04:42:21.561530Z","shell.execute_reply":"2025-02-25T04:42:21.715329Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"from pymilvus import MilvusClient\n\n# Database File obtained from Input dataset\ndatabase_file = \"stock_recommender.db\"\nclient = MilvusClient(database_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:42:21.718733Z","iopub.execute_input":"2025-02-25T04:42:21.719066Z","iopub.status.idle":"2025-02-25T04:42:23.658852Z","shell.execute_reply.started":"2025-02-25T04:42:21.719037Z","shell.execute_reply":"2025-02-25T04:42:23.657373Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"collection_name = \"nr_stock_news\"\n\ncollections = client.list_collections()\nif not collection_name in collections:\n    logger.error(f\"collection_name: {collection_name} not found in database\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:42:23.660527Z","iopub.execute_input":"2025-02-25T04:42:23.661082Z","iopub.status.idle":"2025-02-25T04:42:23.668250Z","shell.execute_reply.started":"2025-02-25T04:42:23.661048Z","shell.execute_reply":"2025-02-25T04:42:23.666906Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def fetch_data_from_collection(client, collection_name):\n    iterator = client.query_iterator(\n        collection_name=collection_name,\n        batch_size=1,\n        output_fields=[\"identifier\", \"timestamp_publish\", \"article\", \"stock_name\"]\n    )\n    \n    results = []\n    while True:\n        result = iterator.next()\n        \n        if not result:\n            iterator.close()\n            break\n        results.append(result)\n    return results\n    \ndata = fetch_data_from_collection(client, collection_name)\nlogger.info(f\"Total data: {len(data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:42:23.669410Z","iopub.execute_input":"2025-02-25T04:42:23.669775Z","iopub.status.idle":"2025-02-25T04:42:23.769923Z","shell.execute_reply.started":"2025-02-25T04:42:23.669740Z","shell.execute_reply":"2025-02-25T04:42:23.768476Z"}},"outputs":[{"name":"stderr","text":"2025-02-25 04:42:23,704 [WARNING][__setup_ts_by_request]: failed to get mvccTs from milvus server, use client-side ts instead (iterator.py:260)\n","output_type":"stream"},{"name":"stdout","text":"2025-02-25 04:42:23,765 - INFO - Total data: 31\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# LLM ","metadata":{}},{"cell_type":"code","source":"import transformers\nfrom torch import cuda\nfrom transformers import AutoTokenizer\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\nlogger.info(f\"Device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:42:23.771008Z","iopub.execute_input":"2025-02-25T04:42:23.771921Z","iopub.status.idle":"2025-02-25T04:42:36.157811Z","shell.execute_reply.started":"2025-02-25T04:42:23.771875Z","shell.execute_reply":"2025-02-25T04:42:36.156724Z"}},"outputs":[{"name":"stdout","text":"2025-02-25 04:42:36,153 - INFO - Device: cpu\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model_id = \"metaresearch/llama-3\"\nmodel_id = \"tiiuae/Falcon3-1B-Instruct\"\n\nmodel_config = transformers.AutoConfig.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    max_new_tokens=1024\n)\n\n\n# # set quantization configuration to load large model with less GPU memory\n# # this requires the `bitsandbytes` library\n# bnb_config = transformers.BitsAndBytesConfig(\n#     load_in_4bit=True,\n#     bnb_4bit_quant_type='nf4',\n#     bnb_4bit_use_double_quant=True,\n#     bnb_4bit_compute_dtype=bfloat16\n# )\n\n# Load model\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    # quantization_config=bnb_config,\n    device_map='auto',\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:42:36.159011Z","iopub.execute_input":"2025-02-25T04:42:36.159553Z","iopub.status.idle":"2025-02-25T04:44:24.981494Z","shell.execute_reply.started":"2025-02-25T04:42:36.159522Z","shell.execute_reply":"2025-02-25T04:44:24.980123Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28bf483117644043bef4c50e220f97a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff0d6b96115b4904b91958650b91551c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/113 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"244d47a556204701a03cb3c1ec4ec25b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/365k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"714f35236c9446f2a7a36574f8918997"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bab0d5db3b34452bb20dafc7548bf0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/826 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"052ddd56b38a4cb1ae5c470a9584bb16"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"query_pipeline = transformers.pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        # torch_dtype=torch.float16,\n        max_length=1024,\n        device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:44:24.983827Z","iopub.execute_input":"2025-02-25T04:44:24.984472Z","iopub.status.idle":"2025-02-25T04:44:25.364161Z","shell.execute_reply.started":"2025-02-25T04:44:24.984440Z","shell.execute_reply":"2025-02-25T04:44:25.362917Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Stock sentiment - LLM without RAG","metadata":{}},{"cell_type":"code","source":"from time import time\n\ndef generate_query_response(tokenizer, pipeline, message):\n    \"\"\"\n    Perform a query\n    print the result\n    Args:\n        tokenizer: the tokenizer\n        pipeline: the pipeline\n        message: the prompt\n    Returns\n        None\n    \"\"\"    \n    time_start = time()\n    sequences = pipeline(\n        message,\n        do_sample=True,\n        top_k=10,\n        num_return_sequences=1,\n        eos_token_id=tokenizer.eos_token_id,\n        max_length=200,)\n    time_end = time()\n    total_time = f\"{round(time_end - time_start, 3)} sec.\"\n    \n    question = sequences[0]['generated_text'][:len(message)]\na    \n    return f\"Question: {question}\\nAnswer: {answer}\\nTotal time: {total_time}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T04:44:25.365539Z","iopub.execute_input":"2025-02-25T04:44:25.365889Z","iopub.status.idle":"2025-02-25T04:44:25.372541Z","shell.execute_reply.started":"2025-02-25T04:44:25.365851Z","shell.execute_reply":"2025-02-25T04:44:25.371291Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"stock_name = \"tata motors\"\nquery = f\"\"\"Assume you are an experianced investor, based on {stock_name} research data and current valuations, \n          you need to come up with eigther to buy, sell, hold. After prediction please mention confidence score between \n          range 0 and 100, after that explain the thought process in less 10 words\"\"\"\nresponse = generate_query_response(tokenizer, query_pipeline, query)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T05:27:49.530726Z","iopub.execute_input":"2025-02-25T05:27:49.533017Z","iopub.status.idle":"2025-02-25T05:28:32.399597Z","shell.execute_reply.started":"2025-02-25T05:27:49.532930Z","shell.execute_reply":"2025-02-25T05:28:32.398089Z"}},"outputs":[{"name":"stdout","text":"Question: Assume you are an experianced investor, based on tata motors research data and current valuations, \n          you need to come up with eigther to buy, sell, hold. After prediction please mention confidence score between \n          range 0 and 100, after that explain the thought process in less 10 words\nAnswer: .\n\n<|assistant|>\nAs an experienced investor, I would analyze Tata Motors' recent financial performance and compare it with current market valuations. With a strong growth trajectory and favorable industry conditions, the stock seems undervalued. I expect a 90% confidence score, indicating a solid buying opportunity. The low valuation and robust financials suggest a promising investment path.\n\n thought process: With strong earnings growth and a solid balance sheet, Tata Motors' stock appears undervalued. A 90% confidence score points to a strong potential for appreciation. Considering market trends and company fundamentals, buying this stock could provide attractive returns.\nTotal time: 42.856 sec.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from langchain.llms import HuggingFacePipeline\n\nllm = HuggingFacePipeline(pipeline=query_pipeline)\nresponse = llm(prompt=query)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T05:28:32.401247Z","iopub.execute_input":"2025-02-25T05:28:32.401531Z","iopub.status.idle":"2025-02-25T05:29:42.599297Z","shell.execute_reply.started":"2025-02-25T05:28:32.401507Z","shell.execute_reply":"2025-02-25T05:29:42.597930Z"}},"outputs":[{"name":"stdout","text":"Assume you are an experianced investor, based on tata motors research data and current valuations, \n          you need to come up with eigther to buy, sell, hold. After prediction please mention confidence score between \n          range 0 and 100, after that explain the thought process in less 10 words.\n\n<|assistant|>\nBased on Tata Motors' latest research and current valuations, I recommend holding. The stock shows strong fundamentals, steady growth potential, and a resilient market position. The confidence score is 85%, indicating a solid outlook.\n\n---\n\n**Thought Process:**\n\n1. **Research Analysis:** Reviewed Tata Motors' latest financial reports, market trends, and industry outlook.\n2. **Valuation Assessment:** Evaluated the stock's intrinsic value relative to its market price.\n3. **Risk Assessment:** Considered potential risks such as economic downturns, competitive pressures, and regulatory changes.\n4. **Trend Analysis:** Identified long-term growth trends and stability in the company's operations.\n5. **Consensus Opinion:** Reviewed market analysts' views and industry experts' recommendations.\n6. **Decision Making:** Based on comprehensive analysis, concluded that holding the stock aligns with my investment strategy and risk tolerance.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\n\nmodel_name = \"sentence-transformers/all-mpnet-base-v2\"\n\nmodel_kwargs = {\"device\": device}\nembeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T05:32:05.559557Z","iopub.execute_input":"2025-02-25T05:32:05.560021Z","iopub.status.idle":"2025-02-25T05:32:15.804612Z","shell.execute_reply.started":"2025-02-25T05:32:05.559986Z","shell.execute_reply":"2025-02-25T05:32:15.802667Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-32-3c41b0628712>:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e07d332fc244fddb5c8bf9c91d20ba4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859fa2a9cbed42be8b975caae8d045ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cff28c03d15640a89593efb564a51efa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2af8080789643aa8aa5a73b1c569d01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3af064d2ccc0441d9bbfe24e9b826f33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e639772b1dc42f2b668b6747e11d68d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"648f9b4097e4472ab4b4ae7f78592d45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dd17b859f824ed0a3ca8312e9363e92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e05b1e12210e4754925632799f4e156e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74a7bc119f2f421c9d41ad1b9e1100b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04024b7614d046d4a0eb29ea5371665f"}},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"from langchain_core.prompts import ChatPromptTemplate\nfrom langchain.chains import create_retrieval_chain\n\ncontext = \"NO CONTEXT IS HERE\"\ninstruction =  f\"\"\"Use the given context to answer the question.\n                  If you don't know the answer, say you don't know.\n                  Use three sentence maximum and keep the answer concise.\n                  Context: {context} \"\"\"\nquery_RAG = f\"{instruction}\\nQuestion: {query}\"\n\nresponse = llm(prompt=query_RAG)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T06:03:59.951749Z","iopub.execute_input":"2025-02-25T06:03:59.952139Z","iopub.status.idle":"2025-02-25T06:04:11.928174Z","shell.execute_reply.started":"2025-02-25T06:03:59.952111Z","shell.execute_reply":"2025-02-25T06:04:11.926824Z"}},"outputs":[{"name":"stdout","text":"Use the given context to answer the question.\n                  If you don't know the answer, say you don't know.\n                  Use three sentence maximum and keep the answer concise.\n                  Context: NO CONTEXT IS HERE \nQuestion: Assume you are an experianced investor, based on tata motors research data and current valuations, \n          you need to come up with eigther to buy, sell, hold. After prediction please mention confidence score between \n          range 0 and 100, after that explain the thought process in less 10 words.\n<|assistant|>\nSell, confidence 70 - Strong bearish sentiment, valuation below target, risk-averse.\n","output_type":"stream"}],"execution_count":39}]}